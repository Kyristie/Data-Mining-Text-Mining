{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e27e6aa-7fa2-4cbe-a956-ed9f9a0dcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837e8e42-2a88-4216-9bfc-8903e93075cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570c0ea4-5041-465e-a599-4a1d72403f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('english_news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbdddbe8-f0a2-4890-8286-9b4d00ac6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lastpart(x):\n",
    "    x=x[1:-1]\n",
    "    x=x.split(',')\n",
    "    return x[-1].replace(\"'\",\"\")\n",
    "df[\"News Categories\"]=df[\"News Categories\"].apply(lastpart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf8466c-50d4-4634-a49c-b7c787e08924",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Encoded Categories'] = le.fit_transform(df['News Categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67e0aba-98dd-4cc5-b0b9-ffa716d15898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category to Number Mapping:\n",
      " Asia_Cup_2023: 0\n",
      " Asian_Games_2022: 1\n",
      " Australian_Open_2024: 2\n",
      " Coronavirus: 3\n",
      " Health___Fitness: 4\n",
      " Hockey_World_Cup_2023: 5\n",
      " Israel-Hamas_War: 6\n",
      " Lifestyle: 7\n",
      " ODI_World_Cup_2023: 8\n",
      " Russia-Ukraine_Conflict: 9\n",
      " business: 10\n",
      " education: 11\n",
      " entertainment: 12\n",
      " facts: 13\n",
      " fashion: 14\n",
      " hatke: 15\n",
      " miscellaneous: 16\n",
      " national: 17\n",
      " policy: 18\n",
      " science: 19\n",
      " sports: 20\n",
      " startup: 21\n",
      " technology: 22\n",
      " travel: 23\n",
      " world: 24\n",
      "Health___Fitness: 25\n",
      "automobile: 26\n",
      "business: 27\n",
      "education: 28\n",
      "entertainment: 29\n",
      "fashion: 30\n",
      "miscellaneous: 31\n",
      "national: 32\n",
      "politics: 33\n",
      "science: 34\n",
      "sports: 35\n",
      "startup: 36\n",
      "technology: 37\n",
      "travel: 38\n",
      "world: 39\n"
     ]
    }
   ],
   "source": [
    "# Show the mapping between the category names and their encoded values\n",
    "category_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"\\nCategory to Number Mapping:\")\n",
    "for category, encoded in category_mapping.items():\n",
    "    print(f\"{category}: {encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a550fb3-f706-407b-8dbd-6b211c4fe9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined_column'] = df['Headline'] + ' ' + df['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e05099-13ae-43e6-b08c-9f91264b2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00a0846-2513-4986-827b-0d5cddbb00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a470286-90d9-4663-bb00-d011fbb11754",
   "metadata": {},
   "source": [
    "# Tdifvectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8812cd-8f84-4a63-817f-10d237329070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SpaCy for lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    # 1. Text Cleaning: Remove non-alphabetic characters and unnecessary symbols\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only alphabetic characters and spaces\n",
    "\n",
    "    # 2. Tokenization: Split text into words (tokens)\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "\n",
    "    # 3. Remove Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 4. Lemmatization (using NLTK's WordNetLemmatizer or SpaCy)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "df_sampled['Combined_column']=df_sampled['Combined_column'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ff6600-0569-4df6-aca0-9007ebd2017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Vectorization: Convert the processed text into numerical form using TF-IDF\n",
    "Tdvectorizer = TfidfVectorizer().fit(df_sampled['Combined_column'])\n",
    "X = Tdvectorizer.transform(df_sampled['Combined_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a168215-38f7-4297-947e-c24ff4818ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8336ba-3a42-45fe-aede-cfd30c64ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sampled['Encoded Categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d20542-e878-4204-89ba-83242d2eb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "027760da-bfc3-4e17-a7bd-865a3255a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549854d6-30f3-44e0-acaa-51170d422d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eb7cb3b-50c0-414a-be8c-eaf2ad1bc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7335\n",
      "Precision: 0.7360814026826044\n",
      "Recall: 0.5396097022425909\n",
      "F1 Score: 0.582606717178027\n"
     ]
    }
   ],
   "source": [
    "# Compute performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a8ad3-7b96-4ca9-91a8-67fe15c3b90b",
   "metadata": {},
   "source": [
    "## Getting Text from Punch News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fadb5833-4eb7-4dad-a906-18c47355cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SpaCy for lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input text\n",
    "text = ['EPL returns: Liverpool play Southampton, Amorim debuts, City target redemption.']\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    # 1. Text Cleaning: Remove non-alphabetic characters and unnecessary symbols\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text[0])  # Keep only alphabetic characters and spaces\n",
    "    \n",
    "    # 2. Tokenization and stop word removal using NLTK\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "    stop_words = set(stopwords.words('english'))  # Set of stopwords from NLTK\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 3. Lemmatization using SpaCy\n",
    "    doc = nlp(' '.join(tokens))  # Create a SpaCy document\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]  # Lemmatize each token\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Preprocess the text\n",
    "cleaned_text = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dee0aac6-debd-405a-8904-dba2f7b3b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vector:\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = preprocess_text(text)\n",
    "\n",
    "cleaned_text_list = [cleaned_text]\n",
    "\n",
    "tfidf_vector = Tdvectorizer.transform(pd.Series(cleaned_text_list))\n",
    "\n",
    "tfidf_array = tfidf_vector.toarray()\n",
    "print(\"TF-IDF Vector:\\n\", tfidf_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747cc71d-22cb-440a-ac1e-fbab8c13f69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 29307)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "762fa7f8-fa0c-491e-a16c-7519ae45e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class= rf_model.predict(tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50d4c1b1-4ece-40f9-84ff-021a28aa9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " national\n"
     ]
    }
   ],
   "source": [
    "for c in category_mapping:\n",
    "    if int(category_mapping[c])==predicted_class:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3462c56-b62f-4d16-b5b0-42d590bdda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SpaCy for lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input text\n",
    "text = ['PDP postpones NEC meeting as N’Central insists on chair.']\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    # 1. Text Cleaning: Remove non-alphabetic characters and unnecessary symbols\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text[0])  # Keep only alphabetic characters and spaces\n",
    "    \n",
    "    # 2. Tokenization and stop word removal using NLTK\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "    stop_words = set(stopwords.words('english'))  # Set of stopwords from NLTK\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 3. Lemmatization using SpaCy\n",
    "    doc = nlp(' '.join(tokens))  # Create a SpaCy document\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]  # Lemmatize each token\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Preprocess the text\n",
    "cleaned_text2 = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e363c5-d365-4a0f-853b-dd1e1e1b1164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vector:\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cleaned_text2 = preprocess_text(text)\n",
    "\n",
    "cleaned_text_list2 = [cleaned_text2]\n",
    "\n",
    "tfidf_vector = Tdvectorizer.transform(pd.Series(cleaned_text_list2))\n",
    "\n",
    "tfidf_array2 = tfidf_vector.toarray()\n",
    "print(\"TF-IDF Vector:\\n\", tfidf_array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f49e8d5-1041-44ea-88de-a2d926a5ae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 29307)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17b893e0-b041-48d2-9855-763df394836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text= rf_model.predict(tfidf_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67a1b0b6-2d04-4706-bafc-642b790eb00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " national\n"
     ]
    }
   ],
   "source": [
    "for c in category_mapping:\n",
    "    if int(category_mapping[c])==predicted_text:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07564c5c-5deb-4d11-b6d0-729d2e1fcf25",
   "metadata": {},
   "source": [
    "# Web Scraping of text from Punch News on 28/11/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "674f1bd0-7b0b-48bc-9698-98cb24e5e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b16a9f56-6104-4007-99be-ba25d239e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://punchng.com/topics/news/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f93973ca-fafd-48df-bf22-d1d9b65acc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"entry-title\"><a href=\"https://punchng.com/uk-opens-africas-largest-visa-application-centre-in-lagos/\">\n",
       "                                                                                                     [ICYMI] UK opens Africa’s largest visa application centre in Lagos </a></h3>,\n",
       " <h3 class=\"entry-title\"><a href=\"https://punchng.com/non-oil-exports-key-to-economic-stability-man/\">\n",
       "                                                                                                     Non-oil exports key to economic stability – MAN </a></h3>,\n",
       " <h3 class=\"entry-title\"><a href=\"https://punchng.com/pictorial-lagos-shuts-churches-hotels-others-over-noise-pollution/\">\n",
       "                                                                                                     PICTORIAL: Lagos shuts churches, hotels, others over noise pollution </a></h3>,\n",
       " <h3 class=\"entry-title\"><a href=\"https://punchng.com/edo-recovers-30-vehicles-from-ex-government-officials/\">\n",
       "                                                                                                     Edo recovers 30 vehicles from ex-government officials </a></h3>,\n",
       " <h3 class=\"entry-title\"><a href=\"https://punchng.com/police-alert-residents-of-security-drill-around-abuja-train-station/\">\n",
       "                                                                                                     Police alert residents of security drill around Abuja train station </a></h3>,\n",
       " <h3 class=\"entry-title\"><a href=\"https://punchng.com/why-i-suspended-health-commissioner-ebonyi-gov/\">\n",
       "                                                                                                     Why I suspended health commissioner – Ebonyi gov </a></h3>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h3', class_ = \"entry-title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8859476-1238-4d18-9fc7-d13ea7de429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = soup.find_all('h3', class_ = \"entry-title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbefd801-226c-4b69-b2e3-2cec86dff501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[ICYMI] UK opens Africa’s largest visa application centre in Lagos',\n",
       " 'Non-oil exports key to economic stability – MAN',\n",
       " 'PICTORIAL: Lagos shuts churches, hotels, others over noise pollution',\n",
       " 'Edo recovers 30 vehicles from ex-government officials',\n",
       " 'Police alert residents of security drill around Abuja train station',\n",
       " 'Why I suspended health commissioner – Ebonyi gov']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [title.text.strip() for title in ttt]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "416c6f0c-8911-431c-afe1-d78f5507dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [ICYMI] UK opens Africa’s largest visa application centre in Lagos\n",
      "Processed: icymi uk open africa large visa application centre lago\n",
      "\n",
      "Original: Non-oil exports key to economic stability – MAN\n",
      "Processed: nonoil export key economic stability man\n",
      "\n",
      "Original: PICTORIAL: Lagos shuts churches, hotels, others over noise pollution\n",
      "Processed: pictorial lago shut church hotel other noise pollution\n",
      "\n",
      "Original: Edo recovers 30 vehicles from ex-government officials\n",
      "Processed: edo recovers vehicle exgovernment official\n",
      "\n",
      "Original: Police alert residents of security drill around Abuja train station\n",
      "Processed: police alert resident security drill around abuja train station\n",
      "\n",
      "Original: Why I suspended health commissioner – Ebonyi gov\n",
      "Processed: suspend health commissioner ebonyi gov\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize SpaCy for lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    # 1. Text Cleaning: Remove non-alphabetic characters and unnecessary symbols\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only alphabetic characters and spaces\n",
    "    \n",
    "    # 2. Tokenization and stop word removal using NLTK\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "    stop_words = set(stopwords.words('english'))  # Set of stopwords from NLTK\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 3. Lemmatization using SpaCy\n",
    "    doc = nlp(' '.join(tokens))  # Create a SpaCy document\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]  # Lemmatize each token\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Process all 6 rows of text\n",
    "processed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "# Print processed texts\n",
    "for original, processed in zip(texts, processed_texts):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Processed: {processed}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b4d2c9e-9833-4e3b-afba-c7b40435afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts_list = [item for sublist in processed_texts for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f3b4c07-9fbe-4ca6-b864-09a907e0ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vector:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "processed_tfidf_vector = Tdvectorizer.transform(pd.Series(processed_texts_list))\n",
    "\n",
    "processed_tfidf_array = processed_tfidf_vector.toarray()\n",
    "print(\"TF-IDF Vector:\\n\", processed_tfidf_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd020079-b3c8-4e50-818a-ea25acca4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_texts = rf_model.predict(processed_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b12e40eb-2a1f-4bac-a68c-924792648efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " national\n"
     ]
    }
   ],
   "source": [
    "for c in category_mapping:\n",
    "    if int(category_mapping[c]) in predicted_texts:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8339b61-52f2-4d44-9d77-a32113c9124a",
   "metadata": {},
   "source": [
    "# Bag-of-Words with Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ba0e0b6-0434-445c-9d8b-5c625b642c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sampled['Combined_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ec73334-6af2-4481-9d6f-91f54f97150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sampled['Encoded Categories']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8143d9-46df-4fa0-8f19-c3933d2b5387",
   "metadata": {},
   "source": [
    "### RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd2b9894-6f33-46b0-9db7-855733d49646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize CountVectorizer for Bag-of-Words (BoW)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the text data into word count vectors\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted vectorizer (same vocabulary)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "308841df-57e7-41ac-8dc2-f3930af1e701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.7448718735590582\n",
      "Recall: 0.5361187890736718\n",
      "F1 Score: 0.5797593915329272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Compute performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af120f-abd4-4422-a667-d7773ca6f644",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a48409d-9984-4374-becc-b40da0136e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.74      0.84      0.79        89\n",
      "           6       0.87      0.65      0.74        31\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.62      0.78      0.69        27\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.87      0.91      0.89        87\n",
      "          11       0.86      0.86      0.86         7\n",
      "          12       0.67      0.31      0.42        13\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.88      0.93      0.91       113\n",
      "          16       1.00      0.20      0.33         5\n",
      "          17       0.63      0.77      0.70       261\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.84      0.64      0.73        25\n",
      "          20       0.83      0.40      0.54        25\n",
      "          21       0.85      0.65      0.73        51\n",
      "          22       0.73      0.81      0.77       204\n",
      "          23       0.88      0.88      0.88       122\n",
      "          24       0.33      0.12      0.18         8\n",
      "          25       0.70      0.60      0.65        43\n",
      "          26       1.00      0.60      0.75        10\n",
      "          27       0.54      0.53      0.54        60\n",
      "          28       0.81      0.52      0.64        42\n",
      "          29       0.83      0.86      0.84       118\n",
      "          30       0.90      0.80      0.85        35\n",
      "          31       0.59      0.74      0.66        90\n",
      "          32       0.50      0.46      0.48        71\n",
      "          33       0.73      0.65      0.69        84\n",
      "          34       0.85      0.85      0.85        97\n",
      "          35       0.76      0.73      0.74        70\n",
      "          36       0.75      0.66      0.70        41\n",
      "          37       0.80      0.58      0.67        55\n",
      "          38       1.00      0.82      0.90        38\n",
      "          39       0.53      0.58      0.55        53\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.66      0.55      0.58      2000\n",
      "weighted avg       0.75      0.74      0.74      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7940afd-b660-45b9-a462-043cba511aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f2ce1-64b9-4fe3-a519-b396fb7c65e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
